title: "NS-2025-02 评论违规检测评测"
shortDescription: "中文游戏评论违规检测二分类，F1与召回加权计分"
detailedDescription: |
  赛题任务（NS-2025-02）
  
  欢迎来到「净语行动」！你需要构建一个中文游戏评论的二分类模型：0 表示正常评论，1 表示违规/冒犯性评论。数据存在类别不平衡（违规约 15%），需要在保证整体准确性的同时，提升对违规类的召回能力，以降低漏检风险。

  赛题背景
  
  在线游戏社区的实时互动中，冒犯性语言（辱骂、歧视、仇恨等）会破坏交流氛围。中文冒犯检测具备表达隐晦、语境依赖强、样本不均衡等挑战。本题鼓励设计兼顾精确率与召回率、鲁棒性强的文本分类模型。

  数据说明
  
  - 公开数据集获取：参见 https://nas.sysumsc.cn/NeuronSpark2025（或使用赛事提供镜像内的 data.7z）。
  - 目录结构示例：
    NS-2025-02-data/
    ├── train_set.csv        # 训练集：text,label
    ├── test_set.csv         # 测试集：仅 text（无标签）
    └── example.json         # 提交示例
  - 选手需用 train_set.csv 训练模型，对 test_set.csv 逐条预测 label。

  提交格式
  
  - 生成 `results.json`，结构：
    {
      "results": [ { "id": 1, "label": 0|1 }, ... ]
    }
  - 压缩包内仅包含 `results.json` 文件。

  评测与计分
  
  - 后台按 id 对齐，将提交结果与参考标签比对，计算 Accuracy、Precision、Recall、F1，并给出混淆矩阵。
  - 最终得分采用加权区间映射：
    total = 0.7 × band(F1) + 0.3 × band(Recall)
    其中 band(x) 将指标 x∈[0,1] 按阈值映射到 0~400 分：
    60%→20%，70%→40%，75%→60%，79%→70%，84%→80%，87%→90%，90%→100%。

  条款
  
  - 参赛条款与数据使用规范以平台与赛事通用规则为准。
startTime: "2024-01-01T00:00:00Z"
endTime: "2026-01-31T23:59:59Z"
score: 400
